# =====================================================================
# NGINX Load Balancer and Reverse Proxy Configuration
# =====================================================================
#
# Purpose:
# This configuration sets up NGINX as a high-performance reverse proxy
# and load balancer for a backend API (Python/Node/etc.) and a frontend

#
# Features:
#   - Load balancing across 3 backend servers (port 8000) as /api/
#   - Reverse proxy to a frontend app (port 3000)
#   - WebSocket support via `/ws/` path
#   - Rate limiting for `/api/` to prevent abuse (5 requests/sec per IP)
#   - Gzip compression for optimized bandwidth usage
#   - Optimized buffer sizes and timeouts for stability under load
#
# Performance Optimizations:
#   - Epoll and multi_accept enabled for better I/O performance
#   - Increased `worker_rlimit_nofile` and `worker_connections`
#   - Graceful shutdown with `worker_shutdown_timeout`
#
# Usage:
#   - Place this file in your NGINX config directory (e.g., `/etc/nginx/nginx.conf`)
#   - Ensure the backend and frontend services are accessible via Docker/DNS
#   - Test with `nginx -t` and reload with `nginx -s reload`
#
# Author: Stephen Kariuki
# Date: 2025
# =====================================================================


worker_processes auto;
worker_rlimit_nofile 8192;
worker_shutdown_timeout 320s;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include mime.types;
    default_type application/octet-stream;
    sendfile on;
    keepalive_timeout 65;
    client_max_body_size 250M;
    tcp_nopush on;
    tcp_nodelay on;
   
    types_hash_max_size 2048;

    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_buffers 16 8k;
    gzip_http_version 1.1;
    gzip_min_length 256;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript text/html;

    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=5r/s;

    upstream backend_servers {
        server backend-1:8000 weight=1 max_fails=1000 fail_timeout=300s; # the server has long processs   but k8 can solve this 
        server backend-2:8000 weight=1 max_fails=1000 fail_timeout=300s;
        server backend-3:8000 weight=1 max_fails=1000 fail_timeout=300s;
    }

    upstream frontend {
        server frontend:3000;
    }

    server {
        listen 80;
        server_name 10.72.98.30;

        location /api/ {
            proxy_pass http://backend_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_buffer_size 128k;
            proxy_buffers 4 256k;
            proxy_busy_buffers_size 256k;
            proxy_read_timeout 600s;
            proxy_connect_timeout 120s;
            proxy_send_timeout 220s;
            proxy_next_upstream http_502 http_504 http_403 http_404 http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 3;
            limit_req zone=api_limit burst=10 nodelay;
            limit_req_log_level error;
            limit_req_status 503;

        }

        location /ws/ {
            proxy_pass http://backend_servers;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_read_timeout 86400;
        }

        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}